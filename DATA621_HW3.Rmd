---
title: "DATA 621 - Group Assignment 3: Logistic Regression on Crime Rates"
author: "(Group 4) Mohamed Hassan-El Serafi, Chun Shing Leung, Keith Colella, Yina,
  Qiao, Eddie Xu"
date: "`r Sys.Date()`"
output: html_document
---

```{r package, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(caret)
library(DataExplorer)
library(psych)
library(car)
```

## Assignment Overview

*In this homework assignment, you will explore, analyze and model a data set containing information on crime for various neighborhoods of a major city. Each record has a response variable indicating whether or not the crime rate is above the median crime rate (1) or not (0).*

## Data Exploration

*Describe the size and the variables in the crime training data set. Consider that too much detail will cause a manager to lose interest while too little detail will make the manager consider that you aren't doing your job.*

```{r crime_training, message=FALSE, warning=FALSE}
# pull in the training data set
crime_training_data <- read.csv("https://raw.githubusercontent.com/eddiexunyc/crime_binary_logistic_regression/refs/heads/main/Resources/crime-training-data_modified.csv")

glimpse(crime_training_data)
```

### Exploratory Data Analysis

A simple exploratory data analysis will be conducted and the training data provided will be used to determine the property and value of the dataset. The `DataExplorer` package will be used to provide a full profile for the data frame.

With the data set given, there are 466 rows and 13 columns. There is no missing values or observations and all columns have continuous values. The `chas` variable is the only dummy variable out of 13 columns and is used to determine if the suburb borders the Charles River. Based on the histograms, both `rm` and `medv` variables are normally distributed, while other variables are skewed. Both `tax` and `rad` variables have very high outliers. This would require log transformation to reduce the skewness for some of these variables. 

```{r data_explorer, warning=FALSE, message=FALSE}
introduce(crime_training_data)

# par on plots
par(mfrow = c(1, 5))
plot_intro(crime_training_data)
describeBy(crime_training_data)
plot_histogram(crime_training_data)
```

Given the box plot below, the variable `chas` has few outliers and the median is close to 0. Not only that, many variables including `indus`, `age`, `ptratio`, `tax` and `rad` are skewed.

Based on the correlation plot, it shows that `rad` and `dis` have the highest positive correlation compared to other variables.

```{r box_plot, warning=FALSE, message=FALSE}
crime_box_plot <- crime_training_data %>%
  gather(key, value, -target) %>% 
  mutate(key = factor(key),
         target = factor(target)) %>% 
  ggplot(aes(x = key, y = value)) +
  geom_boxplot(aes(fill = target)) +
  facet_wrap(~ key, scales = 'free', ncol = 4) +
  scale_fill_manual(values=c("lightblue", "pink")) +
  coord_flip() +
  theme_minimal()

par(mfrow = c(1,2))
crime_box_plot
corPlot(crime_training_data, upper = FALSE)
```

To determine if the dataset is compatible with the binary regression model, the model is fitted and the VIF score analysis is conducted to check for any multicollinearity.

```{r vif_model, warning=FALSE, message=FALSE}
vif_model_all <- lm(target ~ ., data = crime_training_data)

summary(vif_model_all)
```

After the model fitting, the P-value is less than 0.05, showing that predictor variables may be significantly associated with the outcome. There are variables in the data set with moderate correlation between predictor variables. But `rad` and `tax` variables have the highest VIF scores and it is over 5, showing that they are severely correlated with other predictor variables. Therefore, they will be address before modeling the binary regression model.

```{r vif_score, warning=FALSE, message=FALSE}
vif_value = vif(vif_model_all)
vif_value
```

## Data Preparation

*Describe how you have transformed the data by changing the original variables or creating new variables. If you did transform the data or create new variables, discuss why you did this.*

Some of the variables are identified that are skewed, log transformation will be needed to reduce the issue or it will impact the model.

```{r log_transform, message=FALSE, warning=FALSE}
crime_training_data_transformed <- crime_training_data %>%
  mutate(log(crime_training_data$rad + 1),
         log(crime_training_data$dis + 1))
```

These variables `indus`, `age`, `chas`, `ptratio`, and `tax` are skewed and are considered to be removed to determine if the model will be fitted better.

```{r crime_data_remove, message=FALSE, warning=FALSE}
crime_training_data_updated <- crime_training_data %>%
  dplyr::select(-c(indus, age, chas, ptratio, tax))

crime_training_data_updated
```
## Build Models

*Using the training data, build at least three different binary logistic regression models, using different variables (or the same variables with different transformations). You may select the variables manually, use an approach such as Forward or Step wise, use a different approach, or use a combination of techniques. Describe the techniques you used. If you manually selected a variable for inclusion into the model or exclusion into the model, indicate why this was done. Be sure to explain how you can make inferences from the model, as well as discuss other relevant model output.*

### Model 1

The first model is based on the original training data set.

```{r build_model_1, warning=FALSE, message=FALSE}
set.seed(123)
crime_binary_model_1 <- glm(crime_training_data, family = 'binomial', formula = target ~.)
summary(crime_binary_model_1)
plot(crime_binary_model_1)
```

### Model 2
```{r build_model_2, warning=FALSE, message=FALSE}
set.seed(123)
crime_binary_model_2 <- glm(crime_training_data_transformed, family = 'binomial', formula = target ~.)
summary(crime_binary_model_2)
plot(crime_binary_model_2)
```

### Model 3
```{r build_model_3, warning=FALSE, message=FALSE}
set.seed(123)
crime_binary_model_3 <- glm(crime_training_data_updated, family = 'binomial', formula = target ~.)
summary(crime_binary_model_3)
plot(crime_binary_model_3)
```

## Select Model

*Decide on the criteria for selecting the best binary logistic regression model. Will you select models with slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected your model.*

## References

- [Primer on binary logistic regression](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8710907/)
- [R-Blogger: Evaluating Logistic Regression Model](https://www.r-bloggers.com/2015/08/evaluating-logistic-regression-models/#google_vignette)






